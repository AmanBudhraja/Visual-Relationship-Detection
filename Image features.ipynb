{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image features.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1M1At8_2y2wW1tbv0z1nj2XTFVq5JJ6UB","authorship_tag":"ABX9TyPYdaCrKSlnMTzg6jH5J73u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"BCPJgb8lzCTX","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","from numpy import expand_dims\n","from pickle import dump, load\n","from keras.models import Model\n","from readfile import load_vrd_data\n","from keras.preprocessing import image\n","from keras.utils import to_categorical\n","from keras.applications import InceptionV3\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.inception_v3 import preprocess_input"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WczFxGcFKPoq","colab_type":"code","colab":{}},"source":["#Load data from json files\n","df_train, df_valid, df_test = load_vrd_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcCYgkj4KvkQ","colab_type":"code","colab":{}},"source":["#Load the path of images\n","train_img = []\n","img_filename = \"/content/drive/My Drive/visual_relation/sg_train_images/\"\n","for i in range(len(df_train[\"source_img\"])):\n","   train_img.append(img_filename + df_train[\"source_img\"][i])\n","print(len(train_img))\n","\n","val_img = []\n","for i in range(len(df_valid[\"source_img\"])):\n","   val_img.append(img_filename + df_valid[\"source_img\"][i])\n","print(len(val_img))\n","\n","img_filename2 = \"/content/drive/My Drive/visual_relation/sg_test_images/\"\n","test_img = []\n","for i in range(len(df_test[\"source_img\"])):\n","  if df_test[\"source_img\"][i] != \"4392556686_44d71ff5a0_o.jpg\":\n","    test_img.append(img_filename2 + df_test[\"source_img\"][i])\n","print(len(test_img))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8fdsPug6k80","colab_type":"code","colab":{}},"source":["train_label = to_categorical(df_train[\"label\"], num_classes=70) \n","val_label = to_categorical(df_valid[\"label\"], num_classes=70) \n","\n","y_test =[]\n","for i in range(len(df_test[\"label\"])):\n","  if df_test[\"source_img\"][i] != \"4392556686_44d71ff5a0_o.jpg\":\n","    y_test.append(df_test[\"label\"][i])\n","test_label = to_categorical(y_test, num_classes=70) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UxXdCeIBLOeb","colab_type":"code","colab":{}},"source":["#Setting up the inception V3 model\n","original_model    = InceptionV3()\n","bottleneck_input  = original_model.get_layer(index=0).input\n","bottleneck_output = original_model.get_layer(index=-2).output\n","bottleneck_model  = Model(inputs=bottleneck_input, outputs=bottleneck_output)\n","for layer in bottleneck_model.layers:\n","    layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbFZH1ULLxvS","colab_type":"code","colab":{}},"source":["#Extract bounding box information\n","def bboxes(bbox):\n","  xmin = bbox[2]\n","  ymin = bbox[0]\n","  xmax = bbox[3]\n","  ymax = bbox[1]\n","  return xmin,ymin,xmax,ymax\n","\n","#Preprocess the images before extracting features\n","def preprocess(img,df_train,i,x):\n","  img = image.load_img(img)\n","  xmins,ymins,xmaxs,ymaxs = bboxes(df_train[\"subject_bbox\"][i])\n","  xmino,ymino,xmaxo,ymaxo = bboxes(df_train[\"object_bbox\"][i])\n","  if x == \"predicate\":\n","    xminp = min(xmins,xmino)\n","    yminp = min(ymins,ymino)\n","    xmaxp = max(xmaxs,xmaxo)\n","    ymaxp = max(ymaxs,ymaxo)\n","    im_crop = img.crop((xminp,yminp,xmaxp,ymaxp))\n","  elif x == \"subject\":\n","    im_crop = img.crop((xmins,ymins,xmaxs,ymaxs))\n","  elif x == \"object\":\n","    im_crop = img.crop((xmino,ymino,xmaxo,ymaxo))\n","  \n","  im = im_crop.resize((299,299))\n","  im = image.img_to_array(im)\n","  x = np.expand_dims(im, axis=0)\n","  x = preprocess_input(x)\n","  return x\n","\n","#Extract features\n","def encode(img,df_train,i,x):\n","  image = preprocess(img,df_train,i,x)\n","  fec = bottleneck_model.predict(image)\n","  return fec\n","\n","#Create Pickle file\n","def createfile(l,k):\n","  pickle_out = open(l,\"wb\")\n","  dump(k, pickle_out, protocol=4)\n","  pickle_out.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEItkpExqBxa","colab_type":"code","colab":{}},"source":["#Extract features of images\n","clas = [\"predicate\",\"subject\",\"object\"]\n","for z in clas:\n","  with tf.device('/device:GPU:0'):\n","    x_val = []\n","    for i in range(len(val_label)):\n","      x_val.append(encode(val_img[i],df_valid,i,z))\n","    \n","    x_train = []\n","    for i in range(len(train_label)):\n","      x_train.append(encode(train_img[i],df_train,i,z))\n","    \n","    x_test = []\n","    for i in range(len(test_label)):\n","      x_test.append(encode(test_img[i],df_test,i,z))\n","    \n","    x_train = np.array(x_train).reshape(-1,2048)\n","    x_val = np.array(x_val).reshape(-1,2048)\n","    x_test = np.array(x_test).reshape(-1,2048)\n","\n","    q,w,e = z + \"_train.pickle\", z + \"_val.pickle\", z + \"_test.pickle\"\n","    createfile(q,x_train)\n","    createfile(w,x_val)\n","    createfile(e,x_test)"],"execution_count":0,"outputs":[]}]}